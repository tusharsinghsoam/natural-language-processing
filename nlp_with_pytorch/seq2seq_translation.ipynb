{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0852a05",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a39ea0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a5b443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch version: 2.2.2\n",
      "Python 3.11.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Pytorch version:\", torch.__version__)\n",
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28d0104",
   "metadata": {},
   "source": [
    "# Loading data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a72a457",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06282aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3efab520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66453589",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d71c550f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11445 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4601\n",
      "eng 2991\n",
      "['elle est bien connue en tant que chanteuse', 'she s well known as a singer']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d038585",
   "metadata": {},
   "source": [
    "# The Seq2Seq Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2ea861",
   "metadata": {},
   "source": [
    "## The Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ffbb19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a80fbe",
   "metadata": {},
   "source": [
    "## The Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f59a02",
   "metadata": {},
   "source": [
    "### The Simple Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1245305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23657aeb",
   "metadata": {},
   "source": [
    "### Attention Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f2a59eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf94904",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a055dbb4",
   "metadata": {},
   "source": [
    "## Preparing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a3fbc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    return input_lang, output_lang, train_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a156e331",
   "metadata": {},
   "source": [
    "## Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "563103cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21357c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f40c4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    return plot_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1329ae92",
   "metadata": {},
   "source": [
    "# Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fe5fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8666c7",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9894de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abfa0201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3da2215",
   "metadata": {},
   "source": [
    "# Training and Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "287482c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11445 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4601\n",
      "eng 2991\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df5fe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 31s (- 22m 53s) (5 6%) 1.5212\n",
      "3m 0s (- 21m 0s) (10 12%) 0.6777\n",
      "4m 27s (- 19m 19s) (15 18%) 0.3499\n",
      "6m 4s (- 18m 13s) (20 25%) 0.1927\n",
      "7m 32s (- 16m 35s) (25 31%) 0.1180\n",
      "9m 6s (- 15m 10s) (30 37%) 0.0814\n",
      "10m 33s (- 13m 34s) (35 43%) 0.0624\n",
      "12m 5s (- 12m 5s) (40 50%) 0.0507\n",
      "13m 37s (- 10m 35s) (45 56%) 0.0443\n",
      "15m 10s (- 9m 6s) (50 62%) 0.0393\n",
      "17m 0s (- 7m 43s) (55 68%) 0.0361\n",
      "18m 59s (- 6m 19s) (60 75%) 0.0343\n",
      "21m 3s (- 4m 51s) (65 81%) 0.0320\n",
      "22m 30s (- 3m 12s) (70 87%) 0.0312\n",
      "23m 44s (- 1m 34s) (75 93%) 0.0289\n",
      "25m 2s (- 0m 0s) (80 100%) 0.0287\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "plot_losses = train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1679e5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "showPlot(plot_losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f46a970d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> je suis surpris d apprendre ca\n",
      "= i am surprised to learn this\n",
      "< i am surprised to learn this <EOS>\n",
      "\n",
      "> nous nous approchons\n",
      "= we re getting close\n",
      "< we re getting close <EOS>\n",
      "\n",
      "> tu as parfaitement raison\n",
      "= you re perfectly right\n",
      "< you re perfectly right with have two job <EOS>\n",
      "\n",
      "> tu es bon cuisinier non ?\n",
      "= you are a good cook aren t you ?\n",
      "< you are a good cook aren t you ? <EOS>\n",
      "\n",
      "> elle est maigre comme un manche a balai\n",
      "= she is as thin as a broom stick\n",
      "< she is as thin as a broom stick <EOS>\n",
      "\n",
      "> vous etes tellement difficile !\n",
      "= you re so picky\n",
      "< you re so picky <EOS>\n",
      "\n",
      "> tu es fou\n",
      "= you are crazy\n",
      "< you are crazy about it <EOS>\n",
      "\n",
      "> je suis actuellement a l ecole\n",
      "= i m at school now\n",
      "< i m at school now <EOS>\n",
      "\n",
      "> nous sommes debout\n",
      "= we re standing\n",
      "< we re standing <EOS>\n",
      "\n",
      "> je suis heureux avec ce que je possede\n",
      "= i m happy with what i ve got\n",
      "< i m happy with what i ve got <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fa45ee",
   "metadata": {},
   "source": [
    "# Visualizing Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b8f8355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = il n est pas aussi grand que son pere\n",
      "output = he is not as tall as his father <EOS>\n",
      "input = je suis trop fatigue pour conduire\n",
      "output = i m too tired to drive <EOS>\n",
      "input = je suis desole si c est une question idiote\n",
      "output = i m sorry if this is a stupid question <EOS>\n",
      "input = je suis reellement fiere de vous\n",
      "output = i m really proud of you <EOS>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/q8ctftls2p387nv7v_82ptrw0000gp/T/ipykernel_1718/1690937169.py:8: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
      "/var/folders/00/q8ctftls2p387nv7v_82ptrw0000gp/T/ipykernel_1718/1690937169.py:10: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + output_words)\n",
      "/var/folders/00/q8ctftls2p387nv7v_82ptrw0000gp/T/ipykernel_1718/1690937169.py:16: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/var/folders/00/q8ctftls2p387nv7v_82ptrw0000gp/T/ipykernel_1718/1690937169.py:8: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
      "/var/folders/00/q8ctftls2p387nv7v_82ptrw0000gp/T/ipykernel_1718/1690937169.py:10: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + output_words)\n",
      "/var/folders/00/q8ctftls2p387nv7v_82ptrw0000gp/T/ipykernel_1718/1690937169.py:16: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/var/folders/00/q8ctftls2p387nv7v_82ptrw0000gp/T/ipykernel_1718/1690937169.py:8: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
      "/var/folders/00/q8ctftls2p387nv7v_82ptrw0000gp/T/ipykernel_1718/1690937169.py:10: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + output_words)\n",
      "/var/folders/00/q8ctftls2p387nv7v_82ptrw0000gp/T/ipykernel_1718/1690937169.py:16: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/var/folders/00/q8ctftls2p387nv7v_82ptrw0000gp/T/ipykernel_1718/1690937169.py:8: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
      "/var/folders/00/q8ctftls2p387nv7v_82ptrw0000gp/T/ipykernel_1718/1690937169.py:10: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + output_words)\n",
      "/var/folders/00/q8ctftls2p387nv7v_82ptrw0000gp/T/ipykernel_1718/1690937169.py:16: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n",
    "\n",
    "\n",
    "evaluateAndShowAttention('il n est pas aussi grand que son pere')\n",
    "\n",
    "evaluateAndShowAttention('je suis trop fatigue pour conduire')\n",
    "\n",
    "evaluateAndShowAttention('je suis desole si c est une question idiote')\n",
    "\n",
    "evaluateAndShowAttention('je suis reellement fiere de vous')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject-ker",
   "language": "python",
   "name": "myproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
