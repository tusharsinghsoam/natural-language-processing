# About

## Neural Machine Translation with Attention

1. This project demonstrates how to train a sequence-to-sequence (seq2seq) model for Spanish-to-English translation roughly based on [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025v5) (Luong et al., 2015).

2. While this architecture is somewhat outdated, it is still a very useful project to work through to get a deeper understanding of sequence-to-sequence models and attention mechanisms (before going on to [Transformers](transformer.ipynb)).

3. After training the model in this notebook, you will be able to input a Spanish sentence, such as "*Â¿todavia estan en casa?*", and return the English translation: "*are you still at home?*"


## Acknowledgment
1. [Neural machine translation with attention](https://www.tensorflow.org/text/tutorials/nmt_with_attention) tutorial.
